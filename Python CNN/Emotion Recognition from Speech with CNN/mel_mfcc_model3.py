# -*- coding: utf-8 -*-
"""mel&mfcc_model3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IlzMY393sZQbtbX0ET6XWbMdMbO2q69T
"""

# Import libraries 
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from matplotlib.pyplot import specgram
import pandas as pd
import glob 
from sklearn.metrics import confusion_matrix
import IPython.display as ipd  # To play sound in the notebook
import os
import sys
from librosa.util import fix_length
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

X=np.load('/content/drive/MyDrive/data/MEL&MFCC_2D_Augmented/Features_mel_mfcc.npy')
Y2=np.load('/content/drive/MyDrive/data/MEL&MFCC_2D_Augmented/Labels_mel_mfcc.npy')

x_train, x_test, y_train, y_test = train_test_split(X, Y2, random_state=0, test_size=0.2, shuffle=True)
x_train, x_valid, y_train, y_valid =  train_test_split(x_train, y_train, test_size=0.2, random_state=0, shuffle=True)
x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_valid.shape, y_valid.shape

x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],-1)
x_valid=x_valid.reshape(x_valid.shape[0],x_valid.shape[1],x_valid.shape[2],-1)
x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],-1)
x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_valid.shape, y_valid.shape

import keras
from keras.callbacks import ReduceLROnPlateau
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D,Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import os 
import numpy as np
from matplotlib import pyplot, cm
import random
from random import shuffle
import itertools
from tensorflow.keras import datasets, layers, models
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
#!pip install nibabel
import nibabel as nib

from scipy import ndimage
import os
import zipfile
import numpy as np
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from keras.utils.vis_utils import plot_model

class myModel(keras.Model):

  def __init__(self,
      img_dim=550, 
      max_filter_size=32, 
      conv_kernel_size=3,
      pool_kernel_size=2,
      activ_func="relu",
      dropout_ratio=0.2
  ):

    super(myModel,self).__init__()

    self.img_dim = img_dim
    self.max_filter_size = max_filter_size
    self.conv_kernel_size = conv_kernel_size
    self.pool_kernel_size = pool_kernel_size
    self.activ_func = activ_func
    self.dropout_ratio = dropout_ratio

    self.MFCC_features = keras.Sequential(
        
        [     
            layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'),
            #layers.BatchNormalization(), 
            layers.MaxPool2D(pool_size=(2,2), padding = 'same'),
            layers.Dropout(0.3),
         
            layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'),
            #layers.BatchNormalization(), 
            layers.MaxPool2D(pool_size=(2,2), padding = 'same'),
            layers.Dropout(0.3),
         
            layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),
            #layers.BatchNormalization(), 
            layers.MaxPool2D(pool_size=(2,2), padding = 'same'),
            layers.Dropout(0.3),
            
            layers.Flatten()
    ]

  )

    self.Mel_features = keras.Sequential(
        
        [     
            layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'),
            #layers.BatchNormalization(), 
            layers.MaxPool2D(pool_size=(2,2), padding = 'same'),
            layers.Dropout(0.3),
         
            layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'),
            #layers.BatchNormalization(), 
            layers.MaxPool2D(pool_size=(2,2), padding = 'same'),
            layers.Dropout(0.3),
         
            layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'),
            #layers.BatchNormalization(), 
            layers.MaxPool2D(pool_size=(2,2), padding = 'same'),
            layers.Dropout(0.3),
            
            layers.Flatten()
    ]

  )
    
    self.conc_and_pred = keras.Sequential(
        [

            layers.Dense(units=64, activation="relu"),
            layers.BatchNormalization(), 
            layers.Dense(units=6, activation="softmax")

      ]
    )

  def call(self, inputs):

    source1 = inputs[:,:20,:,:]
    source2 = inputs[:,20:,:,:]
    #print(source1.shape)
    #print(source2.shape)

    x1 = self.MFCC_features (source1)
    x2 = self.Mel_features (source2)

    y = tf.concat([x1, x2], 1)
    #print(y.shape)

    output = self.conc_and_pred(y)

    return output

modelALL = myModel(
    
  img_dim=256, 
  max_filter_size=32, 
  conv_kernel_size=3,
  pool_kernel_size=2,
  activ_func="relu",
  dropout_ratio=0.6
  
)

modelALL.compile(optimizer = Adam(learning_rate=0.0001) , loss = 'categorical_crossentropy' , metrics = ['accuracy'])

plot_model(modelALL, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

modelALL.build(input_shape=(None,148,63,1))

modelALL.summary()

history=modelALL.fit(x_train, y_train, batch_size=64, epochs=150, validation_data=(x_valid, y_valid))

keras.models.save_model(modelALL,'/content/drive/MyDrive/7subat2D_mfccmel_2modelseperate_augmented_model3')

modelALL=keras.models.load_model('/content/drive/MyDrive/7subat2D_mfccmel_2modelseperate_augmented_model3')

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy of model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train','test'],loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss of model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train','test'],loc='upper left')
plt.show()

predictions=modelALL.predict(x_test,verbose=0)

#rounding predictions for better perception
rounded_predictions=np.argmax(predictions,axis=1)
roundedy=np.argmax(y_test,axis=1)

#creating confusion matrix
from sklearn.metrics import confusion_matrix, classification_report
cm=confusion_matrix(roundedy,rounded_predictions)

#function for plotting confusion matrix. Normalizing and family classiication can be done with True 
import itertools
def plot_confusion_matrix(cm, classes,
                        normalize=False,
                        title='Confusion matrix',
                        cmap=plt.cm.Blues,
                        ):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """

    plt.figure(figsize=(8, 8))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    #sns.set(font_scale=3.0) #edited as suggested
   
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
        for i in range(6):
          for k in range(6):
            cm[(i,k)]=round(cm[(i,k)],3)
    else:
        print('Confusion matrix, without normalization')
    
    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

cm_plot_labels=['sad', 'angry', 'disgust', 'fear', 'happy', 'neutral']
plot_confusion_matrix(cm=cm,classes=cm_plot_labels, title='Confusion Matrix with Normalization',normalize=True)

plot_confusion_matrix(cm=cm,classes=cm_plot_labels, title='Confusion Matrix without Normalization',normalize=False)

print(classification_report(roundedy, rounded_predictions,target_names=cm_plot_labels))