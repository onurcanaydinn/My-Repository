# -*- coding: utf-8 -*-
"""MelihBasturk_AMC_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R2qg1roJgB7OkPPsRiTpOKTYPpEC3-QY
"""

#Adding needed libraries
import pandas as pd
import numpy as np
import tarfile
import tensorflow as tf
import itertools
import matplotlib.pyplot as plt
import pickle
import random
from random import shuffle
import collections
import itertools
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

#Extracting tar.bz2 file
dosya=tarfile.open("/content/drive/MyDrive/data/RML2016.10a.tar.bz2","r:bz2")
dosya.extractall(path="/content/drive/MyDrive/data")
dosya.close()

#Opening pkl file and read it into data
file=open("/content/drive/MyDrive/data/RML2016.10a_dict.pkl",'rb')
data=pd.read_pickle(file)

data.keys() 
# there are 220 different keys (20 different SNR level) x (11 different modulation types)
#first element of keys is modulation type and second element is SNR level
#according to this we can find each modulation type and SNR levels

# finding modulation types
modulations=[]    
for i in data.keys():    
    if i[0] not in modulations:
        modulations.append(i[0])
modulations

#creating a dictionary to keep different SNR levels
# second element of data.keys() is SNR level 
snr={}
for i in data.keys():
  if i[1] not in snr:
    snr[i[1]]=[]
snr
# 20 different SNR levels between -20dB and 18dB

# encoding modulation types between 1-11
label={}
count=1
for i in modulations:
  label[i]=count 
  count=count+1
label

#one hot encoder: encode as there is only one 1 in each row and others are 0
def onehot_encoder(Label,modtype):
    num_mods=len(Label)
    encoded=np.zeros(num_mods)
    encoded[Label[modtype]-1] = 1
    return encoded

#keeping data(features and labels) in snr according to their snr levels as encoded 
for i in data.keys():
    for k in data[i]:
        snr[i[1]].append([onehot_encoder(label,i[0]),np.array(k)])

snr.keys()

#shuffling before dividing data
for i in snr.keys():  
    shuffle(snr[i])

#dividing dataset to two parts: trainset: without spesific SNR level, SNRset: dict with spesific SNR levels for  
trainset=[]
SNRset= {}

for i in snr.keys():
    trainset.append(snr[i])
    SNRset[i]=snr[i]

len(trainset)

trainset=list(itertools.chain.from_iterable(trainset))

len(trainset)

trainset ## first label(y) then features(x)

#dividing train set into X(input keeps features) and y(output or label).
X=[]
y=[]
for i in trainset:
  y.append(i[0])
  X.append(i[1])

# converting X and y into numpy array to use in train_test_split()
X=np.array(X)
y=np.array(y)

#splitting data into train and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size = 0.1,shuffle=True)

# reshaping X_train and X_valid because model wants 4 dim
X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],-1)
X_valid=X_valid.reshape(X_valid.shape[0],X_valid.shape[1],X_valid.shape[2],-1)

model= Sequential([
                   Conv2D(filters=256, kernel_size=(3,3),activation='relu', padding='same', input_shape=(2,128,1)),
                   BatchNormalization(),
                   MaxPool2D(pool_size=(1,2),padding='valid',data_format=None),
                   Dropout(0.3,input_shape=(2,64,256)),
                   Conv2D(filters=128, kernel_size=(3,3),activation='relu', padding='same', input_shape=(2,64,256)),
                   BatchNormalization(),
                   MaxPool2D(pool_size=(1,2),padding='valid',data_format=None) ,
                   Dropout(0.3,input_shape=(2,32,128)),
                   Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same', input_shape=(2,32,128)),
                   BatchNormalization(),
                   MaxPool2D(pool_size=(1,2),padding='valid',data_format=None),
                   Dropout(0.3,input_shape=(2,16,64)),
                   Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same', input_shape=(2,16,64)),
                   BatchNormalization(),
                   MaxPool2D(pool_size=(1,2),padding='valid',data_format=None)         ,
                   Dropout(0.3, input_shape=(2,8,64)),
                   Flatten(),
                   Dense(units=128, activation='softmax'),
                   BatchNormalization(),
                   Dense(units=11, activation='softmax'),                                         
])

model.summary()

model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])

history=model.fit(X_train,y_train,validation_data=(X_valid, y_valid),batch_size=100,epochs=120)

type(history)

#saving model into drive
model.save('/content/drive/MyDrive/data/sonmodel25eylul.h5')

#loading model from drive
model = keras.models.load_model('/content/drive/MyDrive/data/modelson.h5')

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy of model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train','test'],loc='upper left')
plt.show()
plt.savefig('/content/drive/MyDrive/data/accuracywithepoch120epoch')

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss of model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train','test'],loc='upper left')
plt.show()
plt.savefig('/content/drive/MyDrive/data/losswithepoch120epoch')

predictions=model.predict(X_valid,verbose=0)

#rounding predictions for better perception
rounded_predictions=np.argmax(predictions,axis=1)
roundedy=np.argmax(y_valid,axis=1)

#creating confusion matrix
cmfirst=confusion_matrix(roundedy,rounded_predictions)

#function for plotting confusion matrix. Normalizing and family classiication can be done with True 
def plot_confusion_matrix(cm, classes,
                        normalize=False,
                        title='Confusion matrix',
                        cmap=plt.cm.Blues,
                        family=False):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """

    plt.figure(figsize=(8, 8))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    #sns.set(font_scale=3.0) #edited as suggested

    if family:
      flag=5
    else:
      flag=11      
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
        for i in range(flag):
          for k in range(flag):
            #if cm[(i,k)]< 0.0001:
             # cm[(i,k)]=0
            cm[(i,k)]=round(cm[(i,k)],3)
    else:
        print('Confusion matrix, without normalization')
    
    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

cm_plot_labels=['QPSK', 'PAM4', 'AM-DSB', 'GFSK', 'QAM64', 'AM-SSB', '8PSK','QAM16', 'WBFM', 'CPFSK', 'BPSK']
plot_confusion_matrix(cm=cmfirst,classes=cm_plot_labels, title='Confusion Matrix with Normalization',normalize=True)
plt.savefig('/content/drive/MyDrive/data/CM120/CMallnormalized')

plot_confusion_matrix(cm=cmfirst,classes=cm_plot_labels, title='Confusion Matrix without Normalization',normalize=False)
plt.savefig('/content/drive/MyDrive/data/CM120/CMall')

SNRset.keys()

dB_for_plot=[] 
acc_for_plot=[]
loss_for_plot=[]
acc_for_SNR=[]
for i in sorted(SNRset.keys()): 
    x1=[]
    y1=[]
    for k in SNRset[i]:
        y1.append(k[0])
        x1.append(k[1])
    y1=np.array(y1)
    x1=np.array(x1)
    x1=x1.reshape(x1.shape[0], x1.shape[1], x1.shape[2], 1)
    loss, acc=model.evaluate(x1, y1, verbose=2)
    acc_for_SNR.append([acc, i])
    dB_for_plot.append([i])
    acc_for_plot.append([acc])
    loss_for_plot.append([loss])

acc_for_SNR

#plotting accuracy with SNR 
plt.plot(dB_for_plot,acc_for_plot,marker='o')
plt.xlabel('SNR(dB)')
plt.ylabel('Accuracy')
plt.title('Accuracy with different SNR levels')
plt.xticks(dB_for_plot)
plt.show()
plt.savefig('/content/drive/MyDrive/data/accuracywithSNR120epoch')

#plotting loss with SNR 
plt.plot(dB_for_plot,loss_for_plot,marker='o')
plt.xlabel('SNR(dB)')
plt.ylabel('Loss')
plt.title('Loss with different SNR levels')
plt.xticks(dB_for_plot)
plt.show()
plt.savefig('/content/drive/MyDrive/data/losswithepoch120epoch')

for i in sorted(SNRset.keys()): 
    x2=[]
    y2=[]
    for k in SNRset[i]:
        y2.append(k[0])
        x2.append(k[1]) 
    y2=np.array(y2)
    x2=np.array(x2)
    x2=x2.reshape(x2.shape[0], x2.shape[1], x2.shape[2], 1)
    predictionswithsnr=model.predict(x2,verbose=0)
    rounded_predictionswithsnr=np.argmax(predictionswithsnr,axis=1)
    roundedlabelwithsnr=np.argmax(y2,axis=1)
    cm1=confusion_matrix(roundedlabelwithsnr,rounded_predictionswithsnr)
    plot_confusion_matrix(cm=cm1,classes=cm_plot_labels, title='Confusion Matrix (SNR=%d dB)'%(i),normalize=True)
    plt.savefig('/content/drive/MyDrive/data/CM120/CM(SNR=%d dB).png'%(i))

def type_to_family(cmfirst):
      cm3=np.zeros((5,5))
      cm3[(0,0)]=cmfirst[(2,2)]+cmfirst[(2,5)]+cmfirst[(2,8)]+cmfirst[(5,2)]+cmfirst[(5,5)]+cmfirst[(5,8)]+cmfirst[(8,2)]+cmfirst[(8,5)]+cmfirst[(8,8)]
      cm3[(0,1)]=cmfirst[(2,3)]+cmfirst[(2,9)]+cmfirst[(5,3)]+cmfirst[(5,9)]+cmfirst[(8,3)]+cmfirst[(8,9)]
      cm3[(0,2)]=cmfirst[(2,1)]+cmfirst[(5,1)]+cmfirst[(8,1)]
      cm3[(0,3)]=cmfirst[(2,0)]+cmfirst[(2,6)]+cmfirst[(2,10)]+cmfirst[(5,0)]+cmfirst[(5,6)]+cmfirst[(5,10)]+cmfirst[(8,0)]+cmfirst[(8,6)]+cmfirst[(8,10)]
      cm3[(0,4)]=cmfirst[(2,4)]+cmfirst[(2,7)]+cmfirst[(5,4)]+cmfirst[(5,7)]+cmfirst[(8,4)]+cmfirst[(8,7)]
      
      cm3[(1,0)]=cmfirst[(3,2)]+cmfirst[(3,5)]+cmfirst[(3,8)]+cmfirst[(9,2)]+cmfirst[(9,5)]+cmfirst[(9,8)]
      cm3[(1,1)]=cmfirst[(3,3)]+cmfirst[(3,9)]+cmfirst[(9,3)]+cmfirst[(9,9)]
      cm3[(1,2)]=cmfirst[(3,1)]+cmfirst[(9,1)]
      cm3[(1,3)]=cmfirst[(3,0)]+cmfirst[(3,6)]+cmfirst[(3,10)]+cmfirst[(9,0)]+cmfirst[(9,6)]+cmfirst[(9,10)]
      cm3[(1,4)]=cmfirst[(3,4)]+cmfirst[(3,7)]+cmfirst[(9,4)]+cmfirst[(9,7)]

      cm3[(2,0)]=cmfirst[(1,2)]+cmfirst[(1,5)]+cmfirst[(1,8)]
      cm3[(2,1)]=cmfirst[(1,3)]+cmfirst[(1,9)]
      cm3[(2,2)]=cmfirst[(1,1)]
      cm3[(2,3)]=cmfirst[(1,0)]+cmfirst[(1,6)]+cmfirst[(1,10)]
      cm3[(2,4)]=cmfirst[(1,4)]+cmfirst[(1,7)]

      cm3[(3,0)]=cmfirst[(0,2)]+cmfirst[(0,5)]+cmfirst[(0,8)]+cmfirst[(6,2)]+cmfirst[(6,5)]+cmfirst[(6,8)]+cmfirst[(10,2)]+cmfirst[(10,5)]+cmfirst[(10,8)]
      cm3[(3,1)]=cmfirst[(0,3)]+cmfirst[(0,9)]+cmfirst[(6,3)]+cmfirst[(6,9)]+cmfirst[(10,3)]+cmfirst[(10,9)]
      cm3[(3,2)]=cmfirst[(0,1)]+cmfirst[(6,1)]+cmfirst[(10,1)]
      cm3[(3,3)]=cmfirst[(0,0)]+cmfirst[(0,6)]+cmfirst[(0,10)]+cmfirst[(6,0)]+cmfirst[(6,6)]+cmfirst[(6,10)]+cmfirst[(10,0)]+cmfirst[(10,6)]+cmfirst[(10,10)]
      cm3[(3,4)]=cmfirst[(0,4)]+cmfirst[(0,7)]+cmfirst[(6,4)]+cmfirst[(6,7)]+cmfirst[(10,4)]+cmfirst[(10,7)]

      cm3[(4,0)]=cmfirst[(4,2)]+cmfirst[(4,5)]+cmfirst[(4,8)]+cmfirst[(7,2)]+cmfirst[(7,5)]+cmfirst[(7,8)]
      cm3[(4,1)]=cmfirst[(4,3)]+cmfirst[(4,9)]+cmfirst[(7,3)]+cmfirst[(7,9)]
      cm3[(4,2)]=cmfirst[(4,1)]+cmfirst[(7,1)]
      cm3[(4,3)]=cmfirst[(4,0)]+cmfirst[(4,6)]+cmfirst[(4,10)]+cmfirst[(7,0)]+cmfirst[(7,6)]+cmfirst[(7,10)]
      cm3[(4,4)]=cmfirst[(4,4)]+cmfirst[(4,7)]+cmfirst[(7,4)]+cmfirst[(7,7)]

      return cm3

cm3=type_to_family(cmfirst=cmfirst)
cm3

cm_plot_labels=['Analog', 'FSK', 'PAM', 'PSK', 'QAM']
plot_confusion_matrix(cm=cm3,classes=cm_plot_labels, title='Confusion Matrix',normalize=True,family=True)
plt.savefig('/content/drive/MyDrive/data/CMFamily120/CMFamilyallnormalized')

cm_plot_labels=['Analog', 'FSK', 'PAM', 'PSK', 'QAM']
plot_confusion_matrix(cm=cm3,classes=cm_plot_labels, title='Confusion Matrix',normalize=False,family=True)
plt.savefig('/content/drive/MyDrive/data/CMFamily120/CMFamilyall.png')

for i in sorted(SNRset.keys()): 
    x3=[]
    y3=[]
    for k in SNRset[i]:
        y3.append(k[0])
        x3.append(k[1]) 
    y3=np.array(y3)
    x3=np.array(x3)
    x3=x3.reshape(x3.shape[0], x3.shape[1], x3.shape[2], 1)
    predictionswithsnr=model.predict(x3,verbose=0)
    rounded_predictionswithsnr=np.argmax(predictionswithsnr,axis=1)
    roundedlabelwithsnr=np.argmax(y3,axis=1)
    cm1=confusion_matrix(roundedlabelwithsnr,rounded_predictionswithsnr)
    cm2=type_to_family(cm1)
    cm_plot_labels=['Analog', 'FSK', 'PAM', 'PSK', 'QAM']
    plot_confusion_matrix(cm=cm2,classes=cm_plot_labels, title='Confusion Matrix (SNR=%d dB)'%(i),normalize=True,family=True)
    plt.savefig('/content/drive/MyDrive/data/CMFamily120/CMFamily(SNR=%d dB).png'%(i))