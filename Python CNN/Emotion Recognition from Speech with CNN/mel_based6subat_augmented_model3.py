# -*- coding: utf-8 -*-
"""mel-based6subat_augmented_model3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16FEPSWoO9tBq6qH8HHF11WrsF1uHJpP0
"""

# Import libraries 
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from matplotlib.pyplot import specgram
import pandas as pd
import glob 
from sklearn.metrics import confusion_matrix
import IPython.display as ipd  # To play sound in the notebook
import os
import sys

from google.colab import drive
drive.mount('/content/drive')

x_train=np.load('/content/drive/MyDrive/data_seste/MEL_2D_dB_6Subat_Augmented/x_train.npy')
y_train=np.load('/content/drive/MyDrive/data_seste/MEL_2D_dB_6Subat_Augmented/y_train.npy')
x_valid=np.load('/content/drive/MyDrive/data_seste/MEL_2D_dB_6Subat_Augmented/x_valid.npy')
y_valid=np.load('/content/drive/MyDrive/data_seste/MEL_2D_dB_6Subat_Augmented/y_valid.npy')
x_test=np.load('/content/drive/MyDrive/data_seste/MEL_2D_dB_6Subat_Augmented/x_test.npy')
y_test=np.load('/content/drive/MyDrive/data_seste/MEL_2D_dB_6Subat_Augmented/y_test.npy')

x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_valid.shape, y_valid.shape

import keras
from keras.callbacks import ReduceLROnPlateau
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPool2D,MaxPooling1D,Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization,GlobalAveragePooling2D
from tensorflow.keras.utils import to_categorical
from keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam

model= Sequential([
                   Conv2D(filters=256, kernel_size=(3,3),activation='relu', padding='same', input_shape=(128,63,1)),
                   #BatchNormalization(),
                   MaxPool2D(pool_size=(2,2),padding='valid',data_format=None),
                   Dropout(0.2),
                   Conv2D(filters=128, kernel_size=(3,3),activation='relu', padding='same'),
                   #BatchNormalization(),
                   MaxPool2D(pool_size=(2,2),padding='valid',data_format=None) ,
                   Dropout(0.2),
                   Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same'),
                   #BatchNormalization(),
                   MaxPool2D(pool_size=(2,2),padding='valid',data_format=None),
                   Dropout(0.2),
                   #Conv2D(filters=64, kernel_size=(3,3),activation='relu', padding='same'),
                   #BatchNormalization(),
                   #MaxPool2D(pool_size=(2,2),padding='valid',data_format=None)         ,
                   #Dropout(0.2),
                   Flatten(),
                   Dense(units=64, activation='relu'),
                   BatchNormalization(),
                   Dense(units=6, activation='softmax'),                                         
])

model.summary()
model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy', metrics=['accuracy'])

history=model.fit(x_train, y_train, batch_size=64, epochs=150, validation_data=(x_valid, y_valid))

model.save('/content/drive/MyDrive/6subat2D_mel_augmented_model3.h5')

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy of model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train','valid'],loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss of model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train','valid'],loc='upper left')
plt.show()

predictions=model.predict(x_test,verbose=0)

#rounding predictions for better perception
rounded_predictions=np.argmax(predictions,axis=1)
roundedy=np.argmax(y_test,axis=1)

#creating confusion matrix
from sklearn.metrics import confusion_matrix, classification_report
cm=confusion_matrix(roundedy,rounded_predictions)

#function for plotting confusion matrix. Normalizing and family classiication can be done with True 
import itertools
def plot_confusion_matrix(cm, classes,
                        normalize=False,
                        title='Confusion matrix',
                        cmap=plt.cm.Blues,
                        ):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """

    plt.figure(figsize=(8, 8))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    #sns.set(font_scale=3.0) #edited as suggested
   
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
        for i in range(6):
          for k in range(6):
            cm[(i,k)]=round(cm[(i,k)],3)
    else:
        print('Confusion matrix, without normalization')
    
    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
            horizontalalignment="center",
            color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

cm_plot_labels=['sad', 'angry', 'disgust', 'fear', 'happy', 'neutral']
plot_confusion_matrix(cm=cm,classes=cm_plot_labels, title='Confusion Matrix with Normalization',normalize=True)

plot_confusion_matrix(cm=cm,classes=cm_plot_labels, title='Confusion Matrix without Normalization',normalize=False)

print(classification_report(roundedy, rounded_predictions,target_names=cm_plot_labels))